<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sequence - Your AI Pair Programmer for Algorithms</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;900&family=Roboto+Mono:wght@400;700&display=swap" rel="stylesheet">
    <!-- Orb Dependencies -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.11.4/gsap.min.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #0A0A0A; /* Darker background */
            color: #c9d1d9; 
            /* Grid background */
            background-image:
                linear-gradient(rgba(48, 54, 61, 0.2) 1px, transparent 1px),
                linear-gradient(to right, rgba(48, 54, 61, 0.2) 1px, transparent 1px);
            background-size: 36px 36px;
        }
        .font-mono {
            font-family: 'Roboto Mono', monospace;
        }
        .glass-effect {
            background: rgba(10, 10, 10, 0.7); /* Darker glass effect */
            backdrop-filter: blur(12px);
            -webkit-backdrop-filter: blur(12px);
            border-bottom: 1px solid rgba(48, 54, 61, 0.8);
            box-shadow: 0 4px 30px rgba(0, 0, 0, 0.1);
        }
        .hero-gradient {
            background: radial-gradient(ellipse 50% 50% at 50% -20%, rgba(56, 139, 253, 0.1), #0A0A0A 70%); /* Darker gradient */
        }
        .feature-card:hover .feature-icon {
            transform: scale(1.1);
        }
        .btn-download {
            display: block;
            width: 100%;
            text-align: center;
            padding: 0.75rem 1rem;
            margin-bottom: 0.5rem;
            border: 1px solid #30363d;
            border-radius: 8px; /* Consistent rounding */
            background-color: #21262d;
            transition: all 0.2s ease;
        }
        .btn-download:hover {
            background-color: #30363d;
            border-color: #8b949e;
        }

        /* Scroll offset for fixed header */
        #features {
            scroll-margin-top: 100px;
        }

        /* AI Orb Styles */
        .ai-orb-container { 
            display: flex; 
            flex-direction: column; 
            align-items: center; 
            position: relative;
            height: 500px; /* Fixed height for centering captions in the animation area */
            transition: filter 0.5s, opacity 0.5s;
        }
        .ai-orb-container.paused {
            filter: grayscale(1);
            opacity: 0.5;
        }
        #ai-orb { 
            width: 360px; /* Increased size for HD */
            height: 360px; /* Increased size for HD */
            position: relative; 
            margin: 0 auto;
        }
        #ai-caption { 
            text-align: center; 
            font-weight: 600; 
            /* Reserve fixed height to keep single and double-line captions aligned */
            height: 5rem; /* fixed area for captions (adjustable) */
            color: #c9d1d9;
            position: absolute;
            bottom: 1.5rem; /* lift captions off the bottom edge */
            left: 50%;
            transform: translateX(-50%);
            z-index: 1;
            display: flex;
            flex-direction: column; /* Ensure lines stack vertically */
            align-items: center; /* Center lines horizontally */
            justify-content: center; /* vertically center single-line inside fixed height */
            gap: 0.25rem;
            /* Use same font as demo prompt */
            font-family: 'Inter', sans-serif;
            font-weight: 800;
            width: 100%;
            max-width: 600px;
        }
        
        /* Demo Prompt Styles */
        #demo-prompt-container {
            min-height: 2.5rem;
            margin-top: 1rem;
            margin-bottom: 2rem;
        }
        #demo-prompt {
            color: #ffffff;
            text-align: center;
        }
        .typing-cursor {
            display: inline-block;
            width: 8px;
            height: 1.5rem; /* Adjusted cursor size */
            background-color: #ffffff;
            animation: blink 1s infinite;
            vertical-align: middle;
        }
        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0; }
        }

        /* Advanced Caption Styles */
        .caption-word {
            display: inline;
            transition: all 0.15s ease-in-out;
            margin-right: 0.3rem; /* Increased spacing to match example */
            border-radius: 3px;
            padding: 0 1px;
        }
        .caption-word.current {
            background: rgba(74, 144, 226, 0.5);
            border-radius: 4px;
            padding: 1px 4px;
            box-shadow: 0 0 8px rgba(74, 144, 226, 0.3);
            font-weight: 500;
            transform: scale(1.02);
            color: #fff;
            opacity: 1;
        }
        .caption-word.completed {
            opacity: 0.6;
            color: rgba(255, 255, 255, 0.8);
        }
        .caption-word.upcoming {
            opacity: 0.5;
            color: rgba(255, 255, 255, 0.6);
        }
        .caption-line {
            margin-bottom: 0.5rem;
            line-height: 1.4;
            font-size: 1.5rem; /* text-2xl as in example */
            text-align: center;
            width: 100%;
            font-weight: 800; /* extrabold */
            letter-spacing: -0.025em; /* tracking-tight */
            color: #e6eefc;
        }
        .caption-line.current-line {
            opacity: 1;
        }
        .caption-line.next-line {
            opacity: 0.6;
            font-size: 0.9em;
        }

        /* Keep smaller responsive tweaks but preserve primary sizing */
        @media (max-width: 480px) {
            .caption-line { font-size: 1.1rem; }
            .caption-line.next-line { font-size: 0.95rem; }
            .caption-word { margin-right: 0.2rem; padding: 0 1px; }
        }
        
        /* Scroll Animation Styles */
        .animate-on-scroll {
            opacity: 0;
            transform: translateY(30px);
            transition: opacity 0.6s ease-out, transform 0.6s ease-out;
        }
        .animate-on-scroll.is-visible {
            opacity: 1;
            transform: translateY(0);
        }
    </style>
</head>
<body class="antialiased">

    <!-- Header -->
    <header class="fixed w-full z-30 top-0 glass-effect">
        <div class="max-w-7xl mx-auto px-5 sm:px-6">
            <div class="flex items-center justify-between h-16 md:h-20">
                <!-- Site branding -->
                <div class="flex-shrink-0 mr-4">
                    <a href="#" class="flex items-center">
                         <svg class="h-8" viewBox="0 0 160 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                            <defs>
                                <linearGradient id="logoGradient" x1="0%" y1="0%" x2="100%" y2="0%">
                                    <stop offset="0%" style="stop-color:#d4e6ff;stop-opacity:1" />
                                    <stop offset="100%" style="stop-color:#388BFD;stop-opacity:1" />
                                </linearGradient>
                            </defs>
                            <text x="0" y="19" font-family="'Inter', sans-serif" font-size="24" font-weight="bold" fill="url(#logoGradient)">Sequence</text>
                        </svg>
                    </a>
                </div>

                <!-- Site navigation -->
                <nav class="hidden md:flex md:grow">
                    <ul class="flex grow justify-end flex-wrap items-center">
                        <li><a href="#features" class="text-gray-300 hover:text-white px-4 py-2 flex items-center transition duration-150 ease-in-out">Features</a></li>
                        <li><a href="#setup" class="text-gray-300 hover:text-white px-4 py-2 flex items-center transition duration-150 ease-in-out">Setup</a></li>
                        <li><a href="#pricing" class="text-gray-300 hover:text-white px-4 py-2 flex items-center transition duration-150 ease-in-out">Pricing</a></li>
                        <li><a href="#faq" class="text-gray-300 hover:text-white px-4 py-2 flex items-center transition duration-150 ease-in-out">FAQ</a></li>
                    </ul>
                </nav>
                 <div class="flex items-center">
                     <a href="#" class="hidden sm:inline-block text-gray-300 hover:text-white px-4 py-2 flex items-center transition duration-150 ease-in-out">Log in</a>
                    <a href="#pricing" class="btn text-white bg-blue-600 hover:bg-blue-700 ml-3 rounded-lg px-4 py-2 transition duration-300 ease-in-out">Get Started</a>
                 </div>
            </div>
        </div>
    </header>

    <main class="grow">

        <!-- Hero section -->
        <section class="relative hero-gradient pt-32 pb-20 md:pt-40 md:pb-32">
            <div class="max-w-7xl mx-auto px-4 sm:px-6">
                <div class="text-center">
                    <h1 class="text-4xl md:text-6xl font-extrabold leading-tighter tracking-tighter mb-6 animate-on-scroll">
                        Talk your way through algorithms.
                    </h1>
                    <div class="max-w-3xl mx-auto">
                        <p class="text-lg md:text-xl text-gray-400 mb-10 animate-on-scroll" style="transition-delay: 150ms;">
                           Sequence is a specialized, voice-first AI Partner that remembers your coding journey and delivers a learning experience based on your individual preferences.
                        </p>
                    </div>
                </div>

                <!-- AI Orb -->
                <div class="ai-orb-container" id="ai-orb-container">
                    <div id="ai-orb"></div>
                    <!-- AI Captions and User Prompt -->
                    <div id="ai-caption">
                        <div id="ai-caption-text"></div>
                    </div>
                </div>
                <div id="demo-prompt-container">
                    <p id="demo-prompt" class="text-2xl font-extrabold tracking-tight"></p>
                </div>

            </div>
        </section>

        <!-- Features -->
        <section id="features" class="py-20">
            <div class="max-w-6xl mx-auto px-4 sm:px-6">
             <div class="text-center mb-12">
                 <h2 class="text-3xl md:text-4xl font-extrabold animate-on-scroll">A Smarter Way to Learn</h2>
                     <p class="text-lg text-gray-400 mt-4 animate-on-scroll" style="transition-delay: 150ms;">Sequence is more than a problem bank. It's a complete learning system.</p>
             </div>
                <div class="grid gap-12 md:grid-cols-3">
                    <div class="feature-card text-center animate-on-scroll" style="transition-delay: 200ms;">
                         <div class="feature-icon flex items-center justify-center h-20 w-20 mx-auto mb-4 transition-transform duration-300">
                            <svg class="text-blue-400 w-full h-full" viewBox="0 0 84 36" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true">
                                <!-- Left pill (active) -->
                                <rect x="2" y="10" width="24" height="16" rx="8" stroke="currentColor" stroke-width="3" fill="currentColor" opacity="0.95"/>
                                <!-- Middle pill -->
                                <rect x="30" y="10" width="24" height="16" rx="8" stroke="currentColor" stroke-width="3" fill="none"/>
                                <!-- Right pill -->
                                <rect x="58" y="10" width="24" height="16" rx="8" stroke="currentColor" stroke-width="3" fill="none"/>
                            </svg>
                        </div>
                        <h3 class="text-xl font-bold mb-2">Go Beyond Random Problems</h3>
                        <p class="text-gray-400">Systematically conquer all 14 core algorithmic patterns. A structured curriculum, visual dashboards, and detailed analytics turn random practice into a deliberate path to mastery.</p>
                    </div>
                    <div class="feature-card text-center animate-on-scroll" style="transition-delay: 300ms;">
                         <div class="feature-icon flex items-center justify-center h-20 w-20 mx-auto mb-4 transition-transform duration-300">
                             <svg class="w-12 h-12 text-blue-400" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                                <path d="M12 2L14.5 9.5L22 12L14.5 14.5L12 22L9.5 14.5L2 12L9.5 9.5L12 2Z" stroke="currentColor" stroke-width="2" stroke-linejoin="round"/>
                            </svg>
                        </div>
                        <h3 class="text-xl font-bold mb-2">Intelligent Assistant</h3>
                        <p class="text-gray-400">Get intelligent hints, code explanations, and debugging help from an AI that truly knows you. Powered by a persistent memory of your past sessions, Sequence understands your unique struggles and learning style.</p>
                    </div>
                     <div class="feature-card text-center animate-on-scroll" style="transition-delay: 400ms;">
                         <div class="feature-icon flex items-center justify-center h-20 w-20 mx-auto mb-4 transition-transform duration-300">
                           <svg class="w-12 h-12 text-blue-400" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                                <path d="M4 10V14" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                                <path d="M8 7V17" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                                <path d="M12 4V20" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                                <path d="M16 7V17" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                                <path d="M20 10V14" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                            </svg>
                        </div>
                        <h3 class="text-xl font-bold mb-2">Think Out Loud</h3>
                        <p class="text-gray-400">Speak, don't type. Engage in natural, voice-first conversations to get hints, ask questions, or even have your AI partner walk you through the setup process, step-by-step.</p>
                    </div>
                </div>
                <div class="grid gap-12 md:grid-cols-2 max-w-4xl mx-auto mt-12">
                    <div class="feature-card text-center animate-on-scroll" style="transition-delay: 500ms;">
                        <div class="feature-icon flex items-center justify-center h-20 w-20 mx-auto mb-4 transition-transform duration-300">
                           <img src="brain.svg" class="w-12 h-12 text-blue-400" alt="Brain Icon">
                        </div>
                        <h3 class="text-xl font-bold mb-2">Personalized Guidance</h3>
                        <p class="text-gray-400">Receive contextual hints and code explanations that are tailored to you. Because 'Sequence' remembers your past sessions, its guidance adapts to your unique learning style, helping you when you're stuck without just giving away the answer.</p>
                    </div>
                    <div class="feature-card text-center animate-on-scroll" style="transition-delay: 600ms;">
                        <div class="feature-icon flex items-center justify-center h-20 w-20 mx-auto mb-4 transition-transform duration-300">
                            <svg class="w-12 h-12 text-blue-400" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                                <path d="M8 8L4 12L8 16" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                                <path d="M16 8L20 12L16 16" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                                <path d="M13 4L11 20" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                            </svg>
                        </div>
                        <h3 class="text-xl font-bold mb-2">Coding Agent</h3>
                        <p class="text-gray-400">Go beyond just hints. 'Sequence' acts as your full-time pair programmer. It can write, refactor, and explain code, helping you build and understand complex solutions from the ground up.</p>
                    </div>
                </div>
            </div>
        </section>
        
        <!-- Setup Section -->
        <section id="setup" class="py-20 bg-[#111111]/50">
            <div class="max-w-6xl mx-auto px-4 sm:px-6">
                <div class="text-center mb-12">
                     <h2 class="text-3xl md:text-4xl font-extrabold animate-on-scroll">Set Up in 3 Easy Steps</h2>
                     <p class="text-lg text-gray-400 mt-4 animate-on-scroll" style="transition-delay: 150ms;">Integrate Sequence directly into your editor to start preparing smarter, not just harder.</p>
                </div>
                <div class="max-w-3xl mx-auto">
                    <div class="space-y-12">
                        <!-- Step 1 -->
                        <div class="flex items-start animate-on-scroll">
                            <div class="flex-shrink-0">
                                <div class="flex items-center justify-center h-12 w-12 rounded-full bg-blue-600 text-white font-bold text-xl">1</div>
                            </div>
                            <div class="ml-6">
                                <h3 class="text-2xl font-bold mb-2">Install the Extension</h3>
                                <p class="text-gray-400 mb-6">Get the Sequence extension from the Visual Studio Code marketplace. It's built exclusively for VS Code to ensure a seamless experience.</p>
                                <div class="space-y-2">
                                    <a href="#" class="btn-download rounded-lg">Download for Visual Studio Code</a>
                                </div>
                                <p class="text-xs text-gray-500 mt-4">Available on macOS and Linux. Windows support is experimental (WSL recommended).</p>
                            </div>
                        </div>
                        <!-- Step 2 -->
                        <div class="flex items-start animate-on-scroll" style="transition-delay: 150ms;">
                            <div class="flex-shrink-0">
                                <div class="flex items-center justify-center h-12 w-12 rounded-full bg-blue-600 text-white font-bold text-xl">2</div>
                            </div>
                            <div class="ml-6">
                                <h3 class="text-2xl font-bold mb-2">Sign In & Talk to Sequence</h3>
                                <p class="text-gray-400">Once installed, open the Sequence sidebar and sign in.</p>
                            </div>
                        </div>
                        <!-- Step 3 -->
                        <div class="flex items-start animate-on-scroll" style="transition-delay: 300ms;">
                            <div class="flex-shrink-0">
                                <div class="flex items-center justify-center h-12 w-12 rounded-full bg-blue-600 text-white font-bold text-xl">3</div>
                            </div>
                             <div class="ml-6">
                                <h3 class="text-2xl font-bold mb-2">Configure Your Environment</h3>
                                <ul class="space-y-4 text-gray-300 mt-4">
                                    <li class="flex items-start">
                                        <svg class="w-6 h-6 text-blue-400 mr-3 flex-shrink-0" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 3l7.07 16.97 2.51-7.39 7.39-2.51L3 3z M13 13l6 6"></path></svg>
                                        <span><strong>Use the Dashboard:</strong> Switch between patterns and problems.</span>
                                    </li>
                                     <li class="flex items-start">
                                        <svg class="w-6 h-6 text-blue-400 mr-3 flex-shrink-0" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 4.418-4.03 8-9 8a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.72C3.512 15.042 3 13.574 3 12c0-4.418 4.03-8 9-8s9 3.582 9 8z"></path></svg>
                                        <span><strong>Pair with Sequence:</strong> Ask Sequence for hints, edit code, and understand complex logic seamlessly. Sequence can read files and suggest edits automatically.</span>
                                    </li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Pricing -->
        <section id="pricing" class="py-20 bg-[#111111]/50">
            <div class="max-w-7xl mx-auto px-4 sm:px-6">
                <div class="text-center mb-12">
                    <h2 class="text-3xl md:text-4xl font-extrabold animate-on-scroll">Choose Your Plan</h2>
                    <p class="text-lg text-gray-400 mt-4 animate-on-scroll" style="transition-delay: 150ms;">Start for free, then upgrade for the full AI-powered experience.</p>
                </div>
                <div class="max-w-4xl mx-auto animate-on-scroll" style="transition-delay: 300ms;">
                    <div class="grid md:grid-cols-2 overflow-hidden rounded-3xl border border-[#30363d]">
                        <!-- Free Plan Side -->
                        <div class="p-8 bg-gradient-to-br from-[#0D0D0D] to-[#151515]">
                             <h3 class="text-2xl font-bold mb-2">Free</h3>
                            <p class="text-gray-400 mb-6 min-h-[48px]">The complete pattern mastery toolkit with a generous monthly AI allowance.</p>
                            <div class="flex items-baseline mb-6"><span class="text-4xl font-extrabold">$0</span><span class="ml-2 text-xl font-medium text-gray-400"><sup>USD</sup></span></div>
                            <p class="text-left font-semibold text-white mb-3">What's included:</p>
                            <ul class="text-left space-y-3 mb-8 min-h-[220px]">
                                <li class="flex items-start"><svg class="w-5 h-5 text-green-500 mr-2 flex-shrink-0 mt-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><span>Access to all 14 patterns</span></li>
                                <li class="flex items-start"><svg class="w-5 h-5 text-green-500 mr-2 flex-shrink-0 mt-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><span>238 LeetCode questions with custom tests</span></li>
                                <li class="flex items-start"><svg class="w-5 h-5 text-green-500 mr-2 flex-shrink-0 mt-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><span>20 LLM interactions per month</span></li>
                                <li class="flex items-start"><svg class="w-5 h-5 text-green-500 mr-2 flex-shrink-0 mt-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><span>TTS and STT capabilities</span></li>
                                 <li class="flex items-start"><svg class="w-5 h-5 text-green-500 mr-2 flex-shrink-0 mt-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><span>Adaptive Memory for context</span></li>
                                 <li class="flex items-start"><svg class="w-5 h-5 text-green-500 mr-2 flex-shrink-0 mt-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><span>AI Agent with file read/write</span></li>
                            </ul>
                            <a href="#" class="w-full block text-center bg-gray-800 hover:bg-gray-700 text-white font-bold py-3 px-8 rounded-lg">Start for Free</a>
                        </div>
                        <!-- Pro Plan Side -->
                        <div class="p-8 bg-gradient-to-br from-[#1F1F1F] to-[#191919]">
                            <h3 class="text-2xl font-bold mb-2">Pro</h3>
                            <p class="text-blue-400 mb-6 min-h-[48px]">Unleash the full power of Sequence with unlimited AI.</p>
                            <div class="flex items-baseline mb-6"><span class="text-4xl font-extrabold">$25</span><span class="ml-2 text-xl font-medium text-gray-400"><sup>USD</sup> per month</span></div>
                            <p class="text-left font-semibold text-white mb-3">Everything in Free, plus:</p>
                            <ul class="text-left space-y-3 mb-8 min-h-[220px]">
                                 <li class="flex items-start"><svg class="w-5 h-5 text-green-500 mr-2 flex-shrink-0 mt-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><span><strong>Unlimited</strong> API calls per month</span></li>
                                 <li class="flex items-start"><svg class="w-5 h-5 text-green-500 mr-2 flex-shrink-0 mt-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><span>Advanced AI reasoning</span></li>
                                 <li class="flex items-start"><svg class="w-5 h-5 text-green-500 mr-2 flex-shrink-0 mt-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><span>Increased memory size</span></li>
                            </ul>
                             <a href="#" class="w-full block text-center bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-8 rounded-lg">Go Pro</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- FAQ -->
        <section id="faq" class="py-20">
            <div class="max-w-3xl mx-auto px-4 sm:px-6">
                 <div class="text-center mb-12">
                    <h2 class="text-3xl md:text-4xl font-extrabold animate-on-scroll">Frequently Asked Questions</h2>
                </div>
                <div class="space-y-4">
                    <div class="bg-[#111111] border border-[#30363d] rounded-lg animate-on-scroll" x-data="{ open: false }">
                        <button @click="open = !open" class="w-full flex justify-between items-center text-left text-lg font-semibold p-6">
                            <span>Who is Sequence for?</span>
                            <svg class="w-4 h-4 text-gray-400 transform transition-transform" :class="{'rotate-180': open}" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path d="M19 9l-7 7-7-7"></path></svg>
                        </button>
                        <div x-show="open" x-cloak class="px-6 pb-6 text-gray-400">
                           <p>Sequence is designed for anyone preparing for software engineering technical interviews. If you're tired of aimlessly grinding LeetCode and want a structured, AI-enhanced learning path, Sequence is for you.</p>
                        </div>
                    </div>
                    <div class="bg-[#111111] border border-[#30363d] rounded-lg animate-on-scroll" style="transition-delay: 100ms;" x-data="{ open: false }">
                        <button @click="open = !open" class="w-full flex justify-between items-center text-left text-lg font-semibold p-6">
                            <span>How does the AI assistant work?</span>
                             <svg class="w-4 h-4 text-gray-400 transform transition-transform" :class="{'rotate-180': open}" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path d="M19 9l-7 7-7-7"></path></svg>
                        </button>
                         <div x-show="open" x-cloak class="px-6 pb-6 text-gray-400">
                           <p>Our assistant is powered by Google's Gemini model, providing intelligent, context-aware help in multiple languages. It uses an adaptive memory system to recall your past conversations and problem-solving history, offering personalized hints and explanations that guide you without giving away the answer.</p>
                        </div>
                    </div>
                     <div class="bg-[#111111] border border-[#30363d] rounded-lg animate-on-scroll" style="transition-delay: 200ms;" x-data="{ open: false }">
                        <button @click="open = !open" class="w-full flex justify-between items-center text-left text-lg font-semibold p-6">
                            <span>Can I cancel my subscription?</span>
                             <svg class="w-4 h-4 text-gray-400 transform transition-transform" :class="{'rotate-180': open}" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path d="M19 9l-7 7-7-7"></path></svg>
                        </button>
                         <div x-show="open" x-cloak class="px-6 pb-6 text-gray-400">
                           <p>Absolutely. You can cancel your subscription at any time from your account dashboard. You'll retain access until the end of your current billing period.</p>
                        </div>
                    </div>
                    <div class="bg-[#111111] border border-[#30363d] rounded-lg animate-on-scroll" style="transition-delay: 300ms;" x-data="{ open: false }">
                        <button @click="open = !open" class="w-full flex justify-between items-center text-left text-lg font-semibold p-6">
                            <span>Do you use my data to train your AI models?</span>
                             <svg class="w-4 h-4 text-gray-400 transform transition-transform" :class="{'rotate-180': open}" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path d="M19 9l-7 7-7-7"></path></svg>
                        </button>
                         <div x-show="open" x-cloak class="px-6 pb-6 text-gray-400 space-y-2">
                           <p>No. We do not use your private code, prompts, or suggestions from the Pro plan to train our models.</p>
                        </div>
                    </div>
                     <div class="bg-[#111111] border border-[#30363d] rounded-lg animate-on-scroll" style="transition-delay: 400ms;" x-data="{ open: false }">
                        <button @click="open = !open" class="w-full flex justify-between items-center text-left text-lg font-semibold p-6">
                            <span>What personal data does Sequence process?</span>
                             <svg class="w-4 h-4 text-gray-400 transform transition-transform" :class="{'rotate-180': open}" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path d="M19 9l-7 7-7-7"></path></svg>
                        </button>
                         <div x-show="open" x-cloak class="px-6 pb-6 text-gray-400">
                           <p>We process data required to provide and improve the service. This includes:</p>
                           <ul class="list-disc list-inside mt-2 space-y-1">
                                <li><strong>User Engagement Data:</strong> Pseudonymous data on how you interact with Sequence (e.g., accepted suggestions, feature usage) to help us improve the product.</li>
                                <li><strong>Prompts & Suggestions:</strong> Your inputs to the AI and its generated responses, which are necessary to provide conversational context. On the Pro plan, this data is not retained for model training.</li>
                                <li><strong>Feedback Data:</strong> Any feedback you voluntarily provide through support tickets or in-app reactions.</li>
                           </ul>
                        </div>
                    </div>
                </div>
            </div>
        </section>

    </main>
    
    <!-- Footer -->
    <footer class="bg-[#0A0A0A] border-t border-[#30363d] py-8">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 text-left">
            <div class="text-sm text-gray-400 flex justify-start items-center space-x-4">
                <span>&copy; 2025 Sequence. All rights reserved.</span>
                <a href="#" class="hover:text-white transition-colors">Terms</a>
                <a href="#" class="hover:text-white transition-colors">Privacy</a>
            </div>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/alpinejs@3.x.x/dist/cdn.min.js" defer></script>
    
    <!-- AI Orb Animation Script -->
    <script>
    document.addEventListener('DOMContentLoaded', function() {
        
        // --- AI ORB ANIMATION SYSTEM ---
        let orbScene, orbCamera, orbRenderer, orbParticles, orbParticleMaterial;
        let orbCurrentState = 'idle';
        let orbTime = 0;
        let isOrbInitialized = false;
        let animationFrameId = null;

        const orbConfig = {
            particleCount: 15000, 
            sphereRadius: 120,
            states: {
                idle: { label: "", colors: { highlight1: "#ffffff", highlight2: "#d4e6ff", base1: "#3366cc", base2: "#4488ff" }, secondaryColors: { highlight1: "#f0f0f0", highlight2: "#d4e6ff", base1: "#3366cc", base2: "#4488ff" } },
                listening: { label: "Listening...", colors: { highlight1: "#ffffff", highlight2: "#66ccff", base1: "#0044aa", base2: "#0055dd" }, secondaryColors: { highlight1: "#ffffff", highlight2: "#66ccff", base1: "#66ccff", base2: "#5599ff" } },
                thinking: { label: "Thinking...", colors: { highlight1: "#fff4e6", highlight2: "#ffcc44", base1: "#66aaff", base2: "#4488ff" }, secondaryColors: { highlight1: "#fff4e6", highlight2: "#ff8800", base1: "#77bbff", base2: "#5599ff" } },
                talking: { label: " ", colors: { highlight1: "#ffff44", highlight2: "#44dd44", base1: "#66aaff", base2: "#4488ff" }, secondaryColors: { highlight1: "#ffff44", highlight2: "#ccdd44", base1: "#4488ff", base2: "#4488ff" } }
            }
        };

        let orbPrimaryColors = { highlight1: new THREE.Color(orbConfig.states.idle.colors.highlight1), highlight2: new THREE.Color(orbConfig.states.idle.colors.highlight2), base1: new THREE.Color(orbConfig.states.idle.colors.base1), base2: new THREE.Color(orbConfig.states.idle.colors.base2) };
        let orbSecondaryColors = { highlight1: new THREE.Color(orbConfig.states.idle.secondaryColors.highlight1), highlight2: new THREE.Color(orbConfig.states.idle.secondaryColors.highlight2), base1: new THREE.Color(orbConfig.states.idle.secondaryColors.base1), base2: new THREE.Color(orbConfig.states.idle.secondaryColors.base2) };
        let orbBasePositions = new Float32Array(orbConfig.particleCount * 3);
        let orbParticleCoords = [];

        function initOrb() {
            const container = document.getElementById('ai-orb');
            if (!container || !window.THREE) return false;
            orbScene = new THREE.Scene();
            orbCamera = new THREE.PerspectiveCamera(75, container.clientWidth / container.clientHeight, 0.1, 1000);
            orbCamera.position.z = 250;
            orbRenderer = new THREE.WebGLRenderer({ alpha: true, antialias: true });
            orbRenderer.setSize(container.clientWidth, container.clientHeight);
            orbRenderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
            container.innerHTML = '';
            container.appendChild(orbRenderer.domElement);
            createAdvancedParticleSystem();
            return true;
        }

        function createAdvancedParticleSystem() {
            const geometry = new THREE.BufferGeometry();
            for (let i = 0; i < orbConfig.particleCount; i++) {
                const i3 = i * 3;
                const phi = Math.acos(-1 + (2 * i) / orbConfig.particleCount);
                const theta = Math.sqrt(orbConfig.particleCount * Math.PI) * phi;
                orbParticleCoords.push({ phi, theta });
                orbBasePositions[i3] = orbConfig.sphereRadius * Math.cos(theta) * Math.sin(phi);
                orbBasePositions[i3 + 1] = orbConfig.sphereRadius * Math.sin(theta) * Math.sin(phi);
                orbBasePositions[i3 + 2] = orbConfig.sphereRadius * Math.cos(phi);
            }
            geometry.setAttribute('position', new THREE.BufferAttribute(new Float32Array(orbBasePositions), 3));
            geometry.setAttribute('color', new THREE.BufferAttribute(new Float32Array(orbConfig.particleCount * 3), 3));
            orbParticleMaterial = new THREE.PointsMaterial({ size: 1.5, vertexColors: true, sizeAttenuation: true, blending: THREE.AdditiveBlending, transparent: true, opacity: 0.95 });
            orbParticles = new THREE.Points(geometry, orbParticleMaterial);
            orbScene.add(orbParticles);
        }

        function animateAdvancedOrb() {
            if (!orbRenderer || !orbScene || !orbCamera || !orbParticles) return;
            orbTime += 0.01;
            const positions = orbParticles.geometry.attributes.position.array;
            const colors = orbParticles.geometry.attributes.color.array;
            let syllableIntensity = (orbCurrentState === 'talking') ? 0.5 + Math.sin(orbTime * 10) * 0.3 : 0; // Slower animation
            const highlightPos = new THREE.Vector3(-100, 80, 0);
            const maxDist = 300;
            orbParticles.rotation.y += 0.0005;
            orbParticles.rotation.x += 0.0002;
            orbParticles.updateMatrixWorld();
            const worldMatrix = orbParticles.matrixWorld;
            const pulseFactor = (Math.sin(orbTime * 2) + 1) / 2;
            const h1 = orbPrimaryColors.highlight1.clone().lerp(orbSecondaryColors.highlight1, pulseFactor);
            const h2 = orbPrimaryColors.highlight2.clone().lerp(orbSecondaryColors.highlight2, pulseFactor);
            const b1 = orbPrimaryColors.base1.clone().lerp(orbSecondaryColors.base1, pulseFactor);
            const b2 = orbPrimaryColors.base2.clone().lerp(orbSecondaryColors.base2, pulseFactor);
            const framePalette = [h1, h2, b1, b2];
            for (let i = 0; i < orbConfig.particleCount; i++) {
                const i3 = i * 3;
                const { phi, theta } = orbParticleCoords[i];
                let displacement = 1.0 + (Math.sin(phi * 6 + orbTime * 2) * Math.sin(theta * 6 + orbTime * 2)) * (orbCurrentState === 'talking' ? (0.09 + syllableIntensity * 0.08) : 0.1);
                const localPos = new THREE.Vector3(orbBasePositions[i3] * displacement, orbBasePositions[i3 + 1] * displacement, orbBasePositions[i3 + 2] * displacement);
                positions[i3] = localPos.x; positions[i3 + 1] = localPos.y; positions[i3 + 2] = localPos.z;
                const worldPos = localPos.clone().applyMatrix4(worldMatrix);
                const dist = worldPos.distanceTo(highlightPos);
                const gradientValue = Math.min(1, dist / maxDist);
                const segmentIndex = Math.min(Math.floor(gradientValue * (framePalette.length - 1)), framePalette.length - 2);
                const color1 = framePalette[segmentIndex]; const color2 = framePalette[segmentIndex + 1];
                const localBlendFactor = (gradientValue - (segmentIndex / (framePalette.length - 1))) * (framePalette.length - 1);
                const finalColor = new THREE.Color().copy(color1).lerp(color2, localBlendFactor);
                finalColor.multiplyScalar(1.3);
                colors[i3] = finalColor.r; colors[i3 + 1] = finalColor.g; colors[i3 + 2] = finalColor.b;
            }
            orbParticles.geometry.attributes.position.needsUpdate = true;
            orbParticles.geometry.attributes.color.needsUpdate = true;
            orbRenderer.render(orbScene, orbCamera);
        }

        function startAnimationLoop() {
            if (animationFrameId) return;
            function loop() {
                animateAdvancedOrb();
                animationFrameId = requestAnimationFrame(loop);
            }
            loop();
        }

        function stopAnimationLoop() {
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }
        }

        function setOrbState(stateName) {
            if (!orbConfig.states[stateName] || !window.gsap) return;
            orbCurrentState = stateName;
            const newState = orbConfig.states[stateName];
            const targetPrimary = newState.colors;
            const targetSecondary = newState.secondaryColors;
            for (const key in orbPrimaryColors) {
                gsap.to(orbPrimaryColors[key], { duration: 1.5, r: new THREE.Color(targetPrimary[key]).r, g: new THREE.Color(targetPrimary[key]).g, b: new THREE.Color(targetPrimary[key]).b });
                gsap.to(orbSecondaryColors[key], { duration: 1.5, r: new THREE.Color(targetSecondary[key]).r, g: new THREE.Color(targetSecondary[key]).g, b: new THREE.Color(targetSecondary[key]).b });
            }
            if (orbParticles) {
                gsap.killTweensOf(orbParticles.scale);
                let scaleTarget = { x: 1, y: 1, z: 1 };
                if (stateName === 'listening') scaleTarget = { x: 1.1, y: 1.1, z: 1.1 };
                if (stateName === 'thinking') scaleTarget = { x: 0.9, y: 0.9, z: 0.9 };
                if (stateName === 'talking') scaleTarget = { x: 1.05, y: 1.05, z: 1.05 };
                gsap.to(orbParticles.scale, { duration: 1.5, ...scaleTarget, ease: 'power2.inOut' });
            }
        }
        
        // --- ADVANCED CAPTION SYSTEM ---
        let currentCaptionInterval = null;
        let currentAudio = null;

        function startPreciseCaptions(text, wordBoundaries, audioFile, sequenceIndex) {
            stopCaptions();
            const aiCaptionText = document.getElementById('ai-caption-text');
            if (!aiCaptionText || !text || !wordBoundaries || wordBoundaries.length === 0) return;
            
            const wordsPerLine = 10;
            const chunks = [];
            for (let i = 0; i < wordBoundaries.length; i += wordsPerLine) {
                chunks.push(wordBoundaries.slice(i, i + wordsPerLine));
            }

            const totalDuration = wordBoundaries[wordBoundaries.length - 1].audio_offset + wordBoundaries[wordBoundaries.length - 1].duration;

            // Function to start caption timing
            function startCaptionTiming() {
                let startTime = Date.now();
                currentCaptionInterval = setInterval(() => {
                    const elapsed = (Date.now() - startTime);
                    if (elapsed >= totalDuration) {
                        stopCaptions();
                        setOrbState('idle');
                        document.getElementById('demo-prompt').innerHTML = '';
                        if(aiCaptionText) aiCaptionText.innerHTML = ''; // Clear captions
                        return;
                    }
                    updatePreciseCaptionDisplay(elapsed / 1000, chunks, wordBoundaries);
                }, 16);
            }

            // Use preloaded audio if available
            if (audioFile && sequenceIndex !== undefined && preloadedAudio[sequenceIndex]) {
                currentAudio = preloadedAudio[sequenceIndex].cloneNode();
                currentAudio.currentTime = 0;
                console.log(`Using preloaded audio for sequence ${sequenceIndex + 1}`);
                
                // Start caption timing when audio actually starts playing
                currentAudio.addEventListener('playing', () => {
                    console.log(`Audio ${sequenceIndex + 1} started playing`);
                    startCaptionTiming();
                });
                
                currentAudio.play().catch(e => {
                    console.log('Preloaded audio play failed:', e);
                    // Start captions anyway if audio fails
                    startCaptionTiming();
                });
            } else if (audioFile) {
                // Fallback to loading audio on demand
                console.log(`Fallback: loading audio on demand for ${audioFile}`);
                currentAudio = new Audio('./' + audioFile);
                currentAudio.preload = 'auto';
                
                currentAudio.addEventListener('canplaythrough', () => {
                    currentAudio.play().catch(e => {
                        console.log('Audio play failed:', e);
                        startCaptionTiming();
                    });
                });
                
                currentAudio.addEventListener('playing', () => {
                    startCaptionTiming();
                });
                
                currentAudio.addEventListener('error', (e) => {
                    console.log('Audio loading failed:', e);
                    startCaptionTiming();
                });
                
                currentAudio.load();
            } else {
                // No audio, start captions immediately
                startCaptionTiming();
            }
        }

        function stopCaptions() {
            if (currentCaptionInterval) {
                clearInterval(currentCaptionInterval);
                currentCaptionInterval = null;
            }
            if (currentAudio) {
                currentAudio.pause();
                currentAudio.currentTime = 0;
                currentAudio = null;
            }
        }

        function updatePreciseCaptionDisplay(audioCurrentTime, chunks, wordBoundaries) {
             const aiCaptionText = document.getElementById('ai-caption-text');
            if(!aiCaptionText) return;

            const compensatedTime = audioCurrentTime * 1000; // Work in ms
            let currentWordIndex = -1;
            for (let i = 0; i < wordBoundaries.length; i++) {
                if (compensatedTime >= wordBoundaries[i].audio_offset) {
                    currentWordIndex = i;
                } else {
                    break;
                }
            }
            if (currentWordIndex === -1) return;

            const wordsPerLine = 10;
            const currentChunkIndex = Math.floor(currentWordIndex / wordsPerLine);
            const currentWordInChunk = currentWordIndex % wordsPerLine;

            const currentChunk = chunks[currentChunkIndex];
            const nextChunk = chunks[currentChunkIndex + 1];
            
            let displayHtml = '';
            if(currentChunk) {
                const currentLineHtml = currentChunk.map((boundary, index) => {
                    let className = 'caption-word';
                    if (index < currentWordInChunk) className += ' completed';
                    if (index === currentWordInChunk) className += ' current';
                    return `<span class="${className}">${boundary.text}</span>`;
                }).join(' ');
                displayHtml += `<div class="caption-line current-line">${currentLineHtml}</div>`;
            }

            if (nextChunk) {
                const nextLineHtml = nextChunk.map(boundary => `<span class="caption-word upcoming">${boundary.text}</span>`).join(' ');
                displayHtml += `<div class="caption-line next-line">${nextLineHtml}</div>`;
            }
            
            aiCaptionText.innerHTML = displayHtml;
        }
        
        // --- DEMO LOGIC ---
        let typewriterTimeout = null;
        
        function typeWriter(text, i, fnCallback) {
            const promptEl = document.getElementById("demo-prompt");
            if (!promptEl) return;
            if (i < (text.length)) {
                promptEl.innerHTML = `"${text.substring(0, i+1)}"<span class="typing-cursor"></span>`;
                typewriterTimeout = setTimeout(() => typeWriter(text, i + 1, fnCallback), 50);
                demoTimeouts.push(typewriterTimeout);
            } else {
                promptEl.innerHTML = `"${text}"`;
                if (typeof fnCallback == 'function') {
                    typewriterTimeout = setTimeout(fnCallback, 700);
                    demoTimeouts.push(typewriterTimeout);
                }
            }
        }
        
        function stopTypewriter() {
            if (typewriterTimeout) {
                clearTimeout(typewriterTimeout);
                typewriterTimeout = null;
            }
        }

        let demoHasRun = false;
        let demoStep = 0;
        let demoTimeouts = []; // Track all demo timeouts for cleanup
        let audioPreloaded = false; // Track if audio is preloaded
        let preloadedAudio = []; // Store preloaded audio objects
        
        function preloadAllAudio() {
            const audioFiles = [
                "demo_sequence_1.mp3",
                "demo_sequence_2.mp3", 
                "demo_sequence_3.mp3",
                "demo_sequence_4.mp3",
                "demo_sequence_5.mp3",
                "demo_sequence_6.mp3"
            ];
            
            let loadedCount = 0;
            const totalFiles = audioFiles.length;
            console.log(`Starting to preload ${totalFiles} audio files...`);
            
            audioFiles.forEach((file, index) => {
                const audio = new Audio('./' + file);
                audio.preload = 'auto';
                
                const onLoad = () => {
                    loadedCount++;
                    console.log(`Audio file ${index + 1}/${totalFiles} loaded: ${file}`);
                    if (loadedCount === totalFiles) {
                        audioPreloaded = true;
                        console.log('All audio files preloaded successfully!');
                    }
                    audio.removeEventListener('canplaythrough', onLoad);
                    audio.removeEventListener('error', onError);
                    audio.removeEventListener('loadeddata', onLoad);
                };
                
                const onError = (e) => {
                    loadedCount++; // Count errors as "loaded" to prevent hanging
                    console.warn(`Failed to preload ${file}:`, e);
                    if (loadedCount === totalFiles) {
                        audioPreloaded = true;
                        console.log('Audio preloading complete (some files may have failed)');
                    }
                    audio.removeEventListener('canplaythrough', onLoad);
                    audio.removeEventListener('error', onError);
                    audio.removeEventListener('loadeddata', onLoad);
                };
                
                // Listen to multiple events to ensure we catch when audio is ready
                audio.addEventListener('canplaythrough', onLoad);
                audio.addEventListener('loadeddata', onLoad); // Fallback event
                audio.addEventListener('error', onError);
                
                // Try to load the audio
                try {
                    audio.load();
                    preloadedAudio[index] = audio;
                } catch (e) {
                    console.error(`Error loading ${file}:`, e);
                    onError(e);
                }
            });
            
            // Fallback timeout to prevent indefinite waiting
            setTimeout(() => {
                if (!audioPreloaded) {
                    console.warn('Audio preload timeout reached, forcing completion');
                    audioPreloaded = true;
                }
            }, 8000);
        }
        
        function runDemo() {
            if (!isOrbInitialized || demoHasRun) return;
            
            // Wait for audio to be preloaded before starting demo
            if (!audioPreloaded) {
                console.log('Waiting for audio to preload...');
                // Show loading indicator
                const promptEl = document.getElementById('demo-prompt');
                if (promptEl) promptEl.innerHTML = 'Loading audio...';
                
                const checkPreload = setInterval(() => {
                    if (audioPreloaded) {
                        clearInterval(checkPreload);
                        console.log('Audio preloaded, starting demo');
                        if (promptEl) promptEl.innerHTML = ''; // Clear loading message
                        demoStep = 0;
                        demoHasRun = true;
                        startDemoSequence();
                    }
                }, 100);
                
                // Timeout fallback - start demo anyway after 10 seconds
                setTimeout(() => {
                    if (!demoHasRun) {
                        console.warn('Audio preload timeout, starting demo anyway');
                        clearInterval(checkPreload);
                        if (promptEl) promptEl.innerHTML = '';
                        audioPreloaded = true; // Force it to true
                        demoStep = 0;
                        demoHasRun = true;
                        startDemoSequence();
                    }
                }, 10000);
                return;
            }
            
            demoStep = 0;
            demoHasRun = true;
            startDemoSequence();
        }

        function clearAllDemoTimeouts() {
            demoTimeouts.forEach(timeout => clearTimeout(timeout));
            demoTimeouts = [];
            stopTypewriter(); // Also stop typewriter animation
        }

        function startDemoSequence() {
            const sequences = [
                {
                    prompt: "Can you tell me about yourself?",
                    response: "I'm Sequence, an AI-powered coding assistant designed to help developers master algorithms through personalized, voice-first interactions. I remember our conversations and adapt my guidance to your learning journey.",
                    audioFile: "demo_sequence_1.mp3",
                    wordBoundaries: [
                        { text: "I'm", audio_offset: 105, duration: 223 },
                        { text: "Sequence", audio_offset: 342, duration: 605 },
                        { text: ",", audio_offset: 1039, duration: 118 },
                        { text: "an", audio_offset: 1157, duration: 197 },
                        { text: "AI-powered", audio_offset: 1368, duration: 815 },
                        { text: "coding", audio_offset: 2197, duration: 342 },
                        { text: "assistant", audio_offset: 2552, duration: 473 },
                        { text: "designed", audio_offset: 3039, duration: 434 },
                        { text: "to", audio_offset: 3473, duration: 39 },
                        { text: "help", audio_offset: 3526, duration: 236 },
                        { text: "developers", audio_offset: 3776, duration: 605 },
                        { text: "master", audio_offset: 4394, duration: 552 },
                        { text: "algorithms", audio_offset: 4947, duration: 631 },
                        { text: "through", audio_offset: 5592, duration: 250 },
                        { text: "personalized", audio_offset: 5855, duration: 855 },
                        { text: ",", audio_offset: 6802, duration: 328 },
                        { text: "voice-first", audio_offset: 7131, duration: 723 },
                        { text: "interactions", audio_offset: 7868, duration: 868 },
                        { text: ".", audio_offset: 8750, duration: 92 },
                        { text: "I", audio_offset: 9144, duration: 197 },
                        { text: "remember", audio_offset: 9355, duration: 486 },
                        { text: "our", audio_offset: 9855, duration: 105 },
                        { text: "conversations", audio_offset: 9973, duration: 947 },
                        { text: "and", audio_offset: 11289, duration: 315 },
                        { text: "adapt", audio_offset: 11684, duration: 447 },
                        { text: "my", audio_offset: 12144, duration: 157 },
                        { text: "guidance", audio_offset: 12315, duration: 552 },
                        { text: "to", audio_offset: 13144, duration: 105 },
                        { text: "your", audio_offset: 13250, duration: 105 },
                        { text: "learning", audio_offset: 13355, duration: 315 },
                        { text: "journey", audio_offset: 13684, duration: 473 },
                        { text: ".", audio_offset: 14171, duration: 92 }
                    ]
                },
                {
                    prompt: "Explain the Two Pointers pattern.",
                    response: "The Two Pointers pattern is a technique that uses two separate pointers to traverse a data structure. It's commonly used for problems involving arrays or linked lists where you need to find pairs that satisfy certain conditions.",
                    audioFile: "demo_sequence_2.mp3",
                    wordBoundaries: [
                        { text: "The", audio_offset: 92, duration: 105 },
                        { text: "Two", audio_offset: 210, duration: 250 },
                        { text: "Pointers", audio_offset: 473, duration: 473 },
                        { text: "pattern", audio_offset: 947, duration: 447 },
                        { text: "is", audio_offset: 1460, duration: 105 },
                        { text: "a", audio_offset: 1578, duration: 65 },
                        { text: "technique", audio_offset: 1657, duration: 592 },
                        { text: "that", audio_offset: 2263, duration: 144 },
                        { text: "uses", audio_offset: 2421, duration: 421 },
                        { text: "two", audio_offset: 2855, duration: 302 },
                        { text: "separate", audio_offset: 3171, duration: 381 },
                        { text: "pointers", audio_offset: 3552, duration: 539 },
                        { text: "to", audio_offset: 4381, duration: 78 },
                        { text: "traverse", audio_offset: 4473, duration: 486 },
                        { text: "a", audio_offset: 4960, duration: 52 },
                        { text: "data", audio_offset: 5026, duration: 263 },
                        { text: "structure", audio_offset: 5302, duration: 565 },
                        { text: ".", audio_offset: 5881, duration: 92 },
                        { text: "It's", audio_offset: 6234, duration: 263 },
                        { text: "commonly", audio_offset: 6510, duration: 421 },
                        { text: "used", audio_offset: 6944, duration: 263 },
                        { text: "for", audio_offset: 7207, duration: 118 },
                        { text: "problems", audio_offset: 7326, duration: 473 },
                        { text: "involving", audio_offset: 7813, duration: 447 },
                        { text: "arrays", audio_offset: 8273, duration: 552 },
                        { text: "or", audio_offset: 8839, duration: 250 },
                        { text: "linked", audio_offset: 9102, duration: 355 },
                        { text: "lists", audio_offset: 9471, duration: 394 },
                        { text: "where", audio_offset: 10010, duration: 171 },
                        { text: "you", audio_offset: 10181, duration: 92 },
                        { text: "need", audio_offset: 10286, duration: 171 },
                        { text: "to", audio_offset: 10471, duration: 65 },
                        { text: "find", audio_offset: 10550, duration: 355 },
                        { text: "pairs", audio_offset: 10918, duration: 500 },
                        { text: "that", audio_offset: 11431, duration: 236 },
                        { text: "satisfy", audio_offset: 11668, duration: 644 },
                        { text: "certain", audio_offset: 12326, duration: 342 },
                        { text: "conditions", audio_offset: 12668, duration: 736 },
                        { text: ".", audio_offset: 13418, duration: 92 }
                    ]
                },
                {
                    prompt: "Do you remember when we discussed this pattern before?",
                    response: "I keep track of all our conversations to provide personalized guidance based on your learning journey and past problem-solving experiences. This helps me understand what concepts you've already mastered.",
                    audioFile: "demo_sequence_3.mp3",
                    wordBoundaries: [
                        { text: "I", audio_offset: 92, duration: 171 },
                        { text: "keep", audio_offset: 276, duration: 250 },
                        { text: "track", audio_offset: 526, duration: 381 },
                        { text: "of", audio_offset: 973, duration: 171 },
                        { text: "all", audio_offset: 1263, duration: 210 },
                        { text: "our", audio_offset: 1486, duration: 118 },
                        { text: "conversations", audio_offset: 1618, duration: 750 },
                        { text: "to", audio_offset: 2381, duration: 78 },
                        { text: "provide", audio_offset: 2473, duration: 447 },
                        { text: "personalized", audio_offset: 2921, duration: 671 },
                        { text: "guidance", audio_offset: 3592, duration: 473 },
                        { text: "based", audio_offset: 4197, duration: 342 },
                        { text: "on", audio_offset: 4552, duration: 78 },
                        { text: "your", audio_offset: 4631, duration: 118 },
                        { text: "learning", audio_offset: 4763, duration: 315 },
                        { text: "journey", audio_offset: 5078, duration: 473 },
                        { text: "and", audio_offset: 5828, duration: 342 },
                        { text: "past", audio_offset: 6328, duration: 421 },
                        { text: "problem-solving", audio_offset: 6763, duration: 657 },
                        { text: "experiences", audio_offset: 7434, duration: 894 },
                        { text: ".", audio_offset: 8342, duration: 105 },
                        { text: "This", audio_offset: 8707, duration: 289 },
                        { text: "helps", audio_offset: 9010, duration: 302 },
                        { text: "me", audio_offset: 9326, duration: 144 },
                        { text: "understand", audio_offset: 9471, duration: 736 },
                        { text: "what", audio_offset: 10602, duration: 171 },
                        { text: "concepts", audio_offset: 10786, duration: 684 },
                        { text: "you've", audio_offset: 11484, duration: 236 },
                        { text: "already", audio_offset: 11800, duration: 328 },
                        { text: "mastered", audio_offset: 12142, duration: 657 },
                        { text: ".", audio_offset: 12813, duration: 105 }
                    ]
                },
                {
                    prompt: "How can you help me with coding problems?",
                    response: "I can help you with coding problems by breaking them down step by step, explaining different algorithmic approaches, and providing hints without giving away the complete solution. I adapt to your skill level and learning style.",
                    audioFile: "demo_sequence_4.mp3",
                    wordBoundaries: [
                        { text: "I", audio_offset: 50, duration: 223 },
                        { text: "can", audio_offset: 286, duration: 105 },
                        { text: "help", audio_offset: 405, duration: 197 },
                        { text: "you", audio_offset: 615, duration: 105 },
                        { text: "with", audio_offset: 734, duration: 157 },
                        { text: "coding", audio_offset: 905, duration: 355 },
                        { text: "problems", audio_offset: 1273, duration: 539 },
                        { text: "by", audio_offset: 1826, duration: 157 },
                        { text: "breaking", audio_offset: 1984, duration: 381 },
                        { text: "them", audio_offset: 2378, duration: 144 },
                        { text: "down", audio_offset: 2536, duration: 276 },
                        { text: "step", audio_offset: 2826, duration: 302 },
                        { text: "by", audio_offset: 3142, duration: 131 },
                        { text: "step", audio_offset: 3286, duration: 434 },
                        { text: ",", audio_offset: 3813, duration: 184 },
                        { text: "explaining", audio_offset: 3997, duration: 552 },
                        { text: "different", audio_offset: 4563, duration: 302 },
                        { text: "algorithmic", audio_offset: 4878, duration: 460 },
                        { text: "approaches", audio_offset: 5339, duration: 671 },
                        { text: ",", audio_offset: 6102, duration: 157 },
                        { text: "and", audio_offset: 6260, duration: 328 },
                        { text: "providing", audio_offset: 6589, duration: 447 },
                        { text: "hints", audio_offset: 7036, duration: 368 },
                        { text: "without", audio_offset: 7576, duration: 381 },
                        { text: "giving", audio_offset: 7971, duration: 236 },
                        { text: "away", audio_offset: 8221, duration: 263 },
                        { text: "the", audio_offset: 8497, duration: 105 },
                        { text: "complete", audio_offset: 8602, duration: 355 },
                        { text: "solution", audio_offset: 8971, duration: 578 },
                        { text: ".", audio_offset: 9563, duration: 92 },
                        { text: "I", audio_offset: 9973, duration: 210 },
                        { text: "adapt", audio_offset: 10197, duration: 447 },
                        { text: "to", audio_offset: 10644, duration: 92 },
                        { text: "your", audio_offset: 10750, duration: 92 },
                        { text: "skill", audio_offset: 10855, duration: 328 },
                        { text: "level", audio_offset: 11184, duration: 434 },
                        { text: "and", audio_offset: 11631, duration: 157 },
                        { text: "learning", audio_offset: 11789, duration: 302 },
                        { text: "style", audio_offset: 12105, duration: 565 },
                        { text: ".", audio_offset: 12684, duration: 92 }
                    ]
                },
                {
                    prompt: "What's your approach to teaching algorithms?",
                    response: "My approach focuses on understanding concepts first, then applying them to problems. I use visual explanations, real-world analogies, and build upon previous knowledge to create a strong algorithmic foundation.",
                    audioFile: "demo_sequence_5.mp3",
                    wordBoundaries: [
                        { text: "My", audio_offset: 50, duration: 276 },
                        { text: "approach", audio_offset: 339, duration: 421 },
                        { text: "focuses", audio_offset: 773, duration: 671 },
                        { text: "on", audio_offset: 1510, duration: 276 },
                        { text: "understanding", audio_offset: 1800, duration: 592 },
                        { text: "concepts", audio_offset: 2405, duration: 552 },
                        { text: "first", audio_offset: 2971, duration: 447 },
                        { text: ",", audio_offset: 3510, duration: 289 },
                        { text: "then", audio_offset: 3800, duration: 171 },
                        { text: "applying", audio_offset: 3984, duration: 473 },
                        { text: "them", audio_offset: 4457, duration: 184 },
                        { text: "to", audio_offset: 4655, duration: 92 },
                        { text: "problems", audio_offset: 4760, duration: 736 },
                        { text: ".", audio_offset: 5510, duration: 105 },
                        { text: "I", audio_offset: 5921, duration: 92 },
                        { text: "use", audio_offset: 6026, duration: 276 },
                        { text: "visual", audio_offset: 6302, duration: 434 },
                        { text: "explanations", audio_offset: 6750, duration: 842 },
                        { text: ",", audio_offset: 7684, duration: 355 },
                        { text: "real-world", audio_offset: 8039, duration: 486 },
                        { text: "analogies", audio_offset: 8539, duration: 710 },
                        { text: ",", audio_offset: 9342, duration: 105 },
                        { text: "and", audio_offset: 9447, duration: 276 },
                        { text: "build", audio_offset: 9723, duration: 302 },
                        { text: "upon", audio_offset: 10039, duration: 342 },
                        { text: "previous", audio_offset: 10381, duration: 552 },
                        { text: "knowledge", audio_offset: 10947, duration: 513 },
                        { text: "to", audio_offset: 11473, duration: 92 },
                        { text: "create", audio_offset: 11578, duration: 381 },
                        { text: "a", audio_offset: 11973, duration: 52 },
                        { text: "strong", audio_offset: 12039, duration: 592 },
                        { text: "algorithmic", audio_offset: 12644, duration: 631 },
                        { text: "foundation", audio_offset: 13289, duration: 723 },
                        { text: ".", audio_offset: 14026, duration: 92 }
                    ]
                },
                {
                    prompt: "Can you give me an example of a coding problem?",
                    response: "Sure! Let's look at finding two numbers in an array that add up to a target sum. This is a classic problem that can be solved efficiently using the Two Pointers pattern we discussed earlier.",
                    audioFile: "demo_sequence_6.mp3",
                    wordBoundaries: [
                        { text: "Sure", audio_offset: 52, duration: 513 },
                        { text: "!", audio_offset: 565, duration: 92 },
                        { text: "Let's", audio_offset: 918, duration: 250 },
                        { text: "look", audio_offset: 1181, duration: 157 },
                        { text: "at", audio_offset: 1352, duration: 131 },
                        { text: "finding", audio_offset: 1497, duration: 434 },
                        { text: "two", audio_offset: 1944, duration: 263 },
                        { text: "numbers", audio_offset: 2221, duration: 407 },
                        { text: "in", audio_offset: 2642, duration: 118 },
                        { text: "an", audio_offset: 2760, duration: 65 },
                        { text: "array", audio_offset: 2826, duration: 421 },
                        { text: "that", audio_offset: 3260, duration: 302 },
                        { text: "add", audio_offset: 3576, duration: 184 },
                        { text: "up", audio_offset: 3773, duration: 210 },
                        { text: "to", audio_offset: 4128, duration: 144 },
                        { text: "a", audio_offset: 4286, duration: 78 },
                        { text: "target", audio_offset: 4378, duration: 368 },
                        { text: "sum", audio_offset: 4760, duration: 407 },
                        { text: ".", audio_offset: 5168, duration: 92 },
                        { text: "This", audio_offset: 5523, duration: 355 },
                        { text: "is", audio_offset: 5892, duration: 92 },
                        { text: "a", audio_offset: 5997, duration: 65 },
                        { text: "classic", audio_offset: 6076, duration: 500 },
                        { text: "problem", audio_offset: 6589, duration: 447 },
                        { text: "that", audio_offset: 7050, duration: 144 },
                        { text: "can", audio_offset: 7207, duration: 118 },
                        { text: "be", audio_offset: 7326, duration: 105 },
                        { text: "solved", audio_offset: 7444, duration: 368 },
                        { text: "efficiently", audio_offset: 7878, duration: 671 },
                        { text: "using", audio_offset: 8694, duration: 328 },
                        { text: "the", audio_offset: 9036, duration: 105 },
                        { text: "Two", audio_offset: 9155, duration: 263 },
                        { text: "Pointers", audio_offset: 9418, duration: 513 },
                        { text: "pattern", audio_offset: 9944, duration: 421 },
                        { text: "we", audio_offset: 10378, duration: 92 },
                        { text: "discussed", audio_offset: 10484, duration: 460 },
                        { text: "earlier", audio_offset: 10957, duration: 486 },
                        { text: ".", audio_offset: 11457, duration: 92 }
                    ]
                }
            ];

            if (demoStep >= sequences.length) {
                demoHasRun = false; // Allow replay
                return;
            }

            const sequence = sequences[demoStep];

            setOrbState('listening');
            typeWriter(sequence.prompt, 0, () => {
                setOrbState('thinking');
                const thinkingTimeout = setTimeout(() => {
                    document.getElementById('demo-prompt').innerHTML = '';
                    setOrbState('talking');
                    startPreciseCaptions(sequence.response, sequence.wordBoundaries, sequence.audioFile, demoStep);

                    // Schedule next sequence after current one finishes - add extra buffer time
                    const totalDuration = sequence.wordBoundaries[sequence.wordBoundaries.length - 1].audio_offset +
                                        sequence.wordBoundaries[sequence.wordBoundaries.length - 1].duration;
                    const nextStepTimeout = setTimeout(() => {
                        demoStep++;
                        const nextSequenceTimeout = setTimeout(() => startDemoSequence(), 3000); // Increased pause to 3 seconds between sequences
                        demoTimeouts.push(nextSequenceTimeout);
                    }, totalDuration + 2000); // Increased buffer time to 2 seconds
                    demoTimeouts.push(nextStepTimeout);
                }, 2000);
                demoTimeouts.push(thinkingTimeout);
            });
        }

        // --- ROBUST INITIALIZATION ---
        function initialize() {
            if (!initOrb()) {
                console.error('Advanced orb initialization failed');
                // Optional: show a fallback static image
                const container = document.getElementById('ai-orb');
                if(container) container.innerHTML = `<p style="color: #666;">Animation could not be loaded.</p>`;
                return;
            }
            isOrbInitialized = true;
            startAnimationLoop();
            
            // Start preloading audio files
            preloadAllAudio();
            
            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    const orbContainerEl = document.getElementById('ai-orb-container');
                    if (entry.isIntersecting) {
                        orbContainerEl.classList.remove('paused');
                        startAnimationLoop();
                        // Only run the demo if it hasn't already run since the last exit
                        if (!demoHasRun) runDemo();
                    } else {
                        orbContainerEl.classList.add('paused');
                        stopAnimationLoop();
                        // Stop and clear any running captions / prompt so the demo can replay
                        try {
                            stopCaptions(); // This will stop both captions and audio
                            stopTypewriter(); // Stop typewriter animation
                            clearAllDemoTimeouts(); // Clear all pending timeouts
                            const promptEl = document.getElementById('demo-prompt');
                            if (promptEl) promptEl.innerHTML = '';
                            const captionEl = document.getElementById('ai-caption-text');
                            if (captionEl) captionEl.innerHTML = '';
                            // reset state so runDemo can trigger again when scrolled back
                            demoHasRun = false;
                            demoStep = 0; // Reset demo step to start from beginning
                            setOrbState('idle');
                        } catch (e) {
                            // ignore any errors during cleanup
                            console.warn('Cleanup after leaving viewport failed', e);
                        }
                    }
                });
            }, { threshold: 0.7 });

            const orbContainerEl = document.getElementById('ai-orb-container');
            if (orbContainerEl) {
                observer.observe(orbContainerEl);
            }
            
            // --- SCROLL ANIMATION LOGIC ---
            const scrollObserver = new IntersectionObserver((entries, observer) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('is-visible');
                        observer.unobserve(entry.target);
                    }
                });
            }, { threshold: 0.1 });

            document.querySelectorAll('.animate-on-scroll').forEach(element => {
                scrollObserver.observe(element);
            });
        }

        // Wait for both the DOM and the libraries to be ready.
        let readyCheckInterval = setInterval(() => {
            if (document.readyState === "complete" && window.THREE && window.gsap) {
                clearInterval(readyCheckInterval);
                initialize();
            }
        }, 100);
    });
    </script>
</body>
</html>

